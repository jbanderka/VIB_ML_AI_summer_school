{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJtKd8pZX7bZ"
      },
      "source": [
        "# Advanced Protein Dimer Classification with PyTorch\n",
        "\n",
        "This notebook demonstrates advanced neural network techniques to improve performance on the dimers_features.csv dataset, including normalization, dropout, and model size comparisons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUdce2alX_EN"
      },
      "outputs": [],
      "source": [
        "!pip install torch pandas numpy seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBNSG5AuX7ba"
      },
      "source": [
        "## Learning Objectives\n",
        "- Implement advanced normalization techniques (BatchNorm, LayerNorm, GroupNorm)\n",
        "- Use different dropout strategies and regularization methods\n",
        "- Compare model performance based on architecture size\n",
        "- Apply advanced training techniques (learning rate scheduling, early stopping)\n",
        "- Analyze model complexity vs. performance trade-offs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eI596ANgX7bb",
        "outputId": "56a8d456-0c1b-4f09-846c-0659f2867961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Check PyTorch version and CUDA availability\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "def set_plot_params():\n",
        "    plt.style.use(\"seaborn-v0_8-paper\")\n",
        "    plt.rcParams[\"font.size\"] = 24\n",
        "    sns.set_context(\"paper\", font_scale=1.5)\n",
        "    sns.set_style(\n",
        "        \"ticks\",\n",
        "        {\n",
        "            \"axes.grid\": True,\n",
        "            \"grid.linestyle\": \"--\",\n",
        "            \"grid.alpha\": 0.6,\n",
        "            \"axes.spines.right\": False,\n",
        "            \"axes.spines.top\": False,\n",
        "            \"font.family\": \"serif\",\n",
        "            \"axes.labelpad\": 10,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    colors = [\n",
        "        \"#0173B2\",\n",
        "        \"#DE8F05\",\n",
        "        \"#029E73\",\n",
        "        \"#D55E00\",\n",
        "        \"#CC78BC\",\n",
        "        \"#CA9161\",\n",
        "        \"#FBAFE4\",\n",
        "    ]\n",
        "    sns.set_palette(colors)\n",
        "\n",
        "set_plot_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgA8nYn0X7bd"
      },
      "source": [
        "## 1. Data Loading and Exploration\n",
        "\n",
        "Let's start by loading the dataset and understanding its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "otGWcQn7X7bd",
        "outputId": "0c2cff91-6910-41fc-8d09-e2a8e00872ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-25 13:03:50--  https://github.com/vib-tcp/ml-summerschool-2025/raw/refs/heads/main/topic-4_deep-learning-protein-structures/day_1/dimers_features.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/vib-tcp/ml-summerschool-2025/refs/heads/main/topic-4_deep-learning-protein-structures/day_1/dimers_features.csv [following]\n",
            "--2025-08-25 13:03:50--  https://raw.githubusercontent.com/vib-tcp/ml-summerschool-2025/refs/heads/main/topic-4_deep-learning-protein-structures/day_1/dimers_features.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 971818 (949K) [text/plain]\n",
            "Saving to: ‘dimers_features.csv’\n",
            "\n",
            "dimers_features.csv 100%[===================>] 949.04K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-08-25 13:03:50 (22.1 MB/s) - ‘dimers_features.csv’ saved [971818/971818]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://github.com/vib-tcp/ml-summerschool-2025/raw/refs/heads/main/topic-4_deep-learning-protein-structures/day_1/dimers_features.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KZ5ZfHrlX7bd",
        "outputId": "8f8938e5-d2c2-4461-c3d6-be97403cfce7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Dataset Overview ===\n",
            "Dataset shape: (1677, 69)\n",
            "Number of features: 68\n",
            "\n",
            "Target distribution:\n",
            "physiological\n",
            "False    841\n",
            "True     836\n",
            "Name: count, dtype: int64\n",
            "Physiological ratio: 0.499\n",
            "\n",
            "Missing values:\n",
            "SymmetryOp1    977\n",
            "SymmetryOp2    977\n",
            "gene           149\n",
            "superfamily    248\n",
            "pfam           105\n",
            "dtype: int64\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1677 entries, 0 to 1676\n",
            "Data columns (total 69 columns):\n",
            " #   Column                                      Non-Null Count  Dtype  \n",
            "---  ------                                      --------------  -----  \n",
            " 0   Unnamed: 0                                  1677 non-null   int64  \n",
            " 1   pdb-id                                      1677 non-null   object \n",
            " 2   global_area                                 1677 non-null   float64\n",
            " 3   global_area_per_atom                        1677 non-null   float64\n",
            " 4   global_volume                               1677 non-null   float64\n",
            " 5   global_volume_per_atom                      1677 non-null   float64\n",
            " 6   global_energy                               1677 non-null   float64\n",
            " 7   global_energy_per_atom                      1677 non-null   float64\n",
            " 8   global_sas_area                             1677 non-null   float64\n",
            " 9   global_sas_area_per_atom                    1677 non-null   float64\n",
            " 10  global_sas_energy                           1677 non-null   float64\n",
            " 11  global_sas_energy_per_atom                  1677 non-null   float64\n",
            " 12  global_nonsas_area                          1677 non-null   float64\n",
            " 13  global_nonsas_area_per_atom                 1677 non-null   float64\n",
            " 14  global_nonsas_energy                        1677 non-null   float64\n",
            " 15  global_nonsas_energy_per_atom               1677 non-null   float64\n",
            " 16  interface_atoms                             1677 non-null   int64  \n",
            " 17  interface_area                              1677 non-null   float64\n",
            " 18  interface_energy                            1677 non-null   float64\n",
            " 19  interface_energy_per_atom                   1677 non-null   float64\n",
            " 20  interface_shelled_energy                    1677 non-null   float64\n",
            " 21  interface_shelled_energy_per_atom           1677 non-null   float64\n",
            " 22  interface_expanded_area                     1677 non-null   float64\n",
            " 23  interface_expanded_energy                   1677 non-null   float64\n",
            " 24  interface_expanded_energy_per_atom          1677 non-null   float64\n",
            " 25  interface_expanded_shelled_energy           1677 non-null   float64\n",
            " 26  interface_expanded_shelled_energy_per_atom  1677 non-null   float64\n",
            " 27  split_area                                  1677 non-null   float64\n",
            " 28  split_area_per_atom                         1677 non-null   float64\n",
            " 29  split_volume                                1677 non-null   float64\n",
            " 30  split_volume_per_atom                       1677 non-null   float64\n",
            " 31  split_energy                                1677 non-null   float64\n",
            " 32  split_energy_per_atom                       1677 non-null   float64\n",
            " 33  split_sas_area                              1677 non-null   float64\n",
            " 34  split_sas_area_per_atom                     1677 non-null   float64\n",
            " 35  split_sas_energy                            1677 non-null   float64\n",
            " 36  split_sas_energy_per_atom                   1677 non-null   float64\n",
            " 37  split_nonsas_area                           1677 non-null   float64\n",
            " 38  split_nonsas_area_per_atom                  1677 non-null   float64\n",
            " 39  split_nonsas_energy                         1677 non-null   float64\n",
            " 40  split_nonsas_energy_per_atom                1677 non-null   float64\n",
            " 41  difference_global_area                      1677 non-null   float64\n",
            " 42  difference_global_area_per_atom             1677 non-null   float64\n",
            " 43  difference_global_energy                    1677 non-null   float64\n",
            " 44  difference_global_energy_per_atom           1677 non-null   float64\n",
            " 45  difference_global_volume                    1677 non-null   float64\n",
            " 46  difference_global_volume_per_atom           1677 non-null   float64\n",
            " 47  difference_sas_area                         1677 non-null   float64\n",
            " 48  difference_sas_area_per_atom                1677 non-null   float64\n",
            " 49  difference_sas_energy                       1677 non-null   float64\n",
            " 50  difference_sas_energy_per_atom              1677 non-null   float64\n",
            " 51  difference_nonsas_area                      1677 non-null   float64\n",
            " 52  difference_nonsas_area_per_atom             1677 non-null   float64\n",
            " 53  difference_nonsas_energy                    1677 non-null   float64\n",
            " 54  difference_nonsas_energy_per_atom           1677 non-null   float64\n",
            " 55  ID                                          1677 non-null   object \n",
            " 56  SymmetryOp1                                 700 non-null    object \n",
            " 57  SymmetryOp2                                 700 non-null    object \n",
            " 58  physiological                               1677 non-null   bool   \n",
            " 59  contacts                                    1677 non-null   int64  \n",
            " 60  gene                                        1528 non-null   object \n",
            " 61  superfamily                                 1429 non-null   object \n",
            " 62  pfam                                        1572 non-null   object \n",
            " 63  binding_site_area                           1677 non-null   float64\n",
            " 64  binding_site_area_polar                     1677 non-null   float64\n",
            " 65  binding_site_area_apolar                    1677 non-null   float64\n",
            " 66  fraction_polar                              1677 non-null   float64\n",
            " 67  fraction_apolar                             1677 non-null   float64\n",
            " 68  difficult                                   1677 non-null   bool   \n",
            "dtypes: bool(2), float64(57), int64(3), object(7)\n",
            "memory usage: 881.2+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('dimers_features.csv')\n",
        "\n",
        "print(\"=== Dataset Overview ===\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of features: {len(df.columns) - 1}\")  # Excluding target\n",
        "\n",
        "# Check target distribution\n",
        "target_counts = df['physiological'].value_counts()\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(target_counts)\n",
        "print(f\"Physiological ratio: {target_counts[True] / len(df):.3f}\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(f\"\\nMissing values:\")\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Basic statistics of numerical features\n",
        "print(f\"\\nDataset info:\")\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "And2g_tgX7be"
      },
      "source": [
        "## 2. Feature Selection and Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NOz716NsX7be",
        "outputId": "1f2c9514-97da-40de-a1de-95e3950ec1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of numerical features: 59\n",
            "Features shape: X=(1677, 59), y=(1677,)\n",
            "Train set: (1341, 59), Test set: (336, 59)\n",
            "Train physiological ratio: 0.499\n",
            "Test physiological ratio: 0.497\n"
          ]
        }
      ],
      "source": [
        "categorical_cols = ['pdb-id', 'ID', 'SymmetryOp1', 'SymmetryOp2', 'gene', 'superfamily', 'pfam', \"difficult\", \"Unnamed: 0\"]\n",
        "target_col = 'physiological'\n",
        "\n",
        "# Get numerical columns\n",
        "numerical_cols = [col for col in df.columns if col not in categorical_cols + [target_col]]\n",
        "print(f\"Number of numerical features: {len(numerical_cols)}\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = df[numerical_cols].values\n",
        "y = df[target_col].values\n",
        "\n",
        "print(f\"Features shape: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED, stratify=y # stratify makes sure that the ratios of classes are the same\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n",
        "print(f\"Train physiological ratio: {np.mean(y_train):.3f}\")\n",
        "print(f\"Test physiological ratio: {np.mean(y_test):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPkRGHViX7be"
      },
      "source": [
        "## 3. Normalization Techniques\n",
        "\n",
        "As we noticed, it might be important to normalize our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kThd7GGOX7be"
      },
      "outputs": [],
      "source": [
        "# Compare different normalization techniques\n",
        "print(\"=== Normalization Techniques Comparison ===\")\n",
        "\n",
        "# Test different normalizers\n",
        "normalizers = {\n",
        "    'StandardScaler': StandardScaler(),\n",
        "    'RobustScaler': RobustScaler(),\n",
        "    'MinMaxScaler': MinMaxScaler()\n",
        "}\n",
        "\n",
        "normalizer_results = {}\n",
        "\n",
        "for name, normalizer in normalizers.items():\n",
        "    print(f\"\\nTesting {name}...\")\n",
        "\n",
        "    # Fit and transform\n",
        "    X_train_norm = normalizer.fit_transform(X_train)\n",
        "    X_test_norm = normalizer.transform(X_test)\n",
        "\n",
        "    # Store results\n",
        "    normalizer_results[name] = {\n",
        "        'train': X_train_norm,\n",
        "        'test': X_test_norm,\n",
        "        'normalizer': normalizer\n",
        "    }\n",
        "\n",
        "    # Print statistics\n",
        "    print(f\"Train - Mean: {X_train_norm.mean():.3f}, Std: {X_train_norm.std():.3f}\")\n",
        "    print(f\"Test  - Mean: {X_test_norm.mean():.3f}, Std: {X_test_norm.std():.3f}\")\n",
        "\n",
        "# Use StandardScaler for further analysis (most common choice)\n",
        "best_normalizer = 'StandardScaler'\n",
        "X_train_norm = normalizer_results[best_normalizer]['train']\n",
        "X_test_norm = normalizer_results[best_normalizer]['test']\n",
        "\n",
        "print(f\"\\nUsing {best_normalizer} for further analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx1jNGXVX7bf"
      },
      "source": [
        "## 4. Advanced Neural Network Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnLh2k-iX7bf"
      },
      "outputs": [],
      "source": [
        "# Base model class\n",
        "class AdvancedDimerClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, num_classes=2,\n",
        "                 dropout_rate=0.3, normalization='batch', activation='relu'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.normalization = normalization\n",
        "        self.activation = activation\n",
        "\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        # Build hidden layers with advanced techniques\n",
        "        for i, hidden_size in enumerate(hidden_sizes):\n",
        "            # Linear layer\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "\n",
        "            # Normalization layer\n",
        "            if normalization == 'batch':\n",
        "                layers.append(nn.BatchNorm1d(hidden_size))\n",
        "            elif normalization == 'layer':\n",
        "                layers.append(nn.LayerNorm(hidden_size))\n",
        "\n",
        "\n",
        "            # Activation function\n",
        "            if activation == 'relu':\n",
        "                layers.append(nn.ReLU())\n",
        "            elif activation == 'leaky_relu':\n",
        "                layers.append(nn.LeakyReLU(0.1))\n",
        "            elif activation == 'sigmoid':\n",
        "                layers.append(nn.Sigmoid())\n",
        "\n",
        "            if i < len(hidden_sizes) - 1:  # No dropout after last hidden layer\n",
        "                if dropout_rate > 0:\n",
        "                    layers.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # Output layer\n",
        "        layers.append(nn.Linear(prev_size, num_classes))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvIRDfH6X7bf"
      },
      "source": [
        "Create different models for our experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcsV8AmdX7bf"
      },
      "outputs": [],
      "source": [
        "def create_model_architectures(input_size):\n",
        "    \"\"\"Create different model architectures for comparison\"\"\"\n",
        "    architectures = {\n",
        "        'Logistic_Regression': [1],\n",
        "        'Large': [128, 64, 32, 16],\n",
        "    }\n",
        "    dropout_rates = [0.0, 0.25]\n",
        "    normalizations = [\"none\", \"batch\"]\n",
        "    activations = [\"relu\", \"sigmoid\"]\n",
        "\n",
        "    models = {}\n",
        "    for name, hidden_sizes in architectures.items():\n",
        "        for dropout_rate in dropout_rates:\n",
        "            for normalization in normalizations:\n",
        "                for activation in activations:\n",
        "                    model_name = f\"{name}_dropout_{dropout_rate}_norm_{normalization}_act_{activation}\"\n",
        "                    models[model_name] = AdvancedDimerClassifier(\n",
        "                        input_size=input_size,\n",
        "                        hidden_sizes=hidden_sizes,\n",
        "                        dropout_rate=dropout_rate,\n",
        "                        normalization=normalization,\n",
        "                        activation=activation\n",
        "                    )\n",
        "\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZWhvE4-X7bf"
      },
      "outputs": [],
      "source": [
        "input_size = X_train_norm.shape[1]\n",
        "models = create_model_architectures(input_size)\n",
        "\n",
        "print(\"=== Model Architectures ===\")\n",
        "for name, model in models.items():\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"{name} Model: {total_params:,} parameters ({trainable_params:,} trainable)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2KaCq9sX7bg"
      },
      "source": [
        "## 5. Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CrtVeo3X7bg"
      },
      "outputs": [],
      "source": [
        "def train_model_advanced(model, train_loader, test_loader,\n",
        "                        criterion, optimizer, scheduler,\n",
        "                        num_epochs, device, patience=15):\n",
        "    \"\"\"Advanced training with validation and early stopping\"\"\"\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_features, batch_labels in train_loader:\n",
        "            batch_features = batch_features.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_features)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += batch_labels.size(0)\n",
        "            train_correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_features, batch_labels in test_loader:\n",
        "                batch_features = batch_features.to(device)\n",
        "                batch_labels = batch_labels.to(device)\n",
        "\n",
        "                outputs = model(batch_features)\n",
        "                loss = criterion(outputs, batch_labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += batch_labels.size(0)\n",
        "                val_correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        train_acc = train_correct / train_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "            scheduler.step(avg_val_loss)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Store metrics\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            # Save best model\n",
        "            torch.save(model.state_dict(), f'best_model_{model.__class__.__name__}.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch:3d}: Train Loss = {avg_train_loss:.4f}, Train Acc = {train_acc:.4f}')\n",
        "            print(f'           Val Loss = {avg_val_loss:.4f}, Val Acc = {val_acc:.4f}')\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f'Early stopping at epoch {epoch}')\n",
        "            break\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0GtLX74X7bg"
      },
      "source": [
        "## 6. Data Preparation and Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ8506JxX7bg"
      },
      "outputs": [],
      "source": [
        "class ProteinDimerDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "train_dataset = ProteinDimerDataset(X_train_norm, y_train)\n",
        "test_dataset = ProteinDimerDataset(X_test_norm, y_test)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train loader: {len(train_loader)} batches\")\n",
        "print(f\"Test loader: {len(test_loader)} batches\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSfjz3WxX7bh"
      },
      "source": [
        "## 7. Model Training and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3zPJswmX7bh"
      },
      "outputs": [],
      "source": [
        "num_epochs = 250\n",
        "learning_rate = 0.001\n",
        "weight_decay = 1e-4\n",
        "\n",
        "model_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {model_name} Model\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # We didn't use AdamW in the previous notebook, but it's a good optimizer for this task\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=10,\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    train_losses, test_losses, train_accuracies, test_accuracies = train_model_advanced(\n",
        "        model, train_loader, test_loader, criterion, optimizer, scheduler,\n",
        "        num_epochs, device, patience=20\n",
        "    )\n",
        "\n",
        "    # Store results\n",
        "    model_results[model_name] = {\n",
        "        'model': model,\n",
        "        'train_losses': train_losses,\n",
        "        'test_losses': test_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'test_accuracies': test_accuracies\n",
        "    }\n",
        "\n",
        "    print(f\"{model_name} Test Accuracy: {test_accuracies[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppOglnh5X7bh"
      },
      "source": [
        "# 8. Performance Analysis and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzdfOLtXX7bh"
      },
      "outputs": [],
      "source": [
        "# Plot training progress for all models\n",
        "plt.figure(figsize=(30, 12))\n",
        "\n",
        "# Training losses\n",
        "plt.subplot(1, 3, 1)\n",
        "for name, results in model_results.items():\n",
        "    plt.plot(results['train_losses'], label=f'{name} Train', alpha=0.7)\n",
        "plt.title('Training Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation losses\n",
        "plt.subplot(1, 3, 2)\n",
        "for name, results in model_results.items():\n",
        "    plt.plot(results['test_losses'], label=f'{name} Test', alpha=0.7)\n",
        "plt.title('Test Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Training accuracies\n",
        "plt.subplot(1, 3, 3)\n",
        "for name, results in model_results.items():\n",
        "    plt.plot(results['train_accuracies'], label=f'{name} Train', alpha=0.7)\n",
        "plt.title('Training Accuracies')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYw_-Z3aX7bj"
      },
      "outputs": [],
      "source": [
        "# Plot training progress for all models\n",
        "plt.figure(figsize=(17, 35))\n",
        "\n",
        "# Validation accuracies\n",
        "plt.subplot(3, 1, 1)\n",
        "for name, results in model_results.items():\n",
        "    plt.plot(results['test_accuracies'], label=f'{name} Test', alpha=0.7)\n",
        "plt.title('Test Accuracies')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Model size vs performance\n",
        "plt.subplot(3, 1, 2)\n",
        "model_sizes = []\n",
        "test_accuracies = []\n",
        "for name, results in model_results.items():\n",
        "    model = results['model']\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    model_sizes.append(total_params)\n",
        "    test_accuracies.append(results['test_accuracies'][-1])\n",
        "\n",
        "plt.scatter(model_sizes, test_accuracies, s=100, alpha=0.7)\n",
        "for i, name in enumerate(model_results.keys()):\n",
        "    plt.annotate(name, (model_sizes[i], test_accuracies[i]),\n",
        "                xytext=(5, 5), textcoords='offset points')\n",
        "plt.xlabel('Number of Parameters')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Model Size vs Performance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Final test accuracies comparison\n",
        "plt.subplot(3, 1, 3)\n",
        "names = list(model_results.keys())\n",
        "accuracies = [model_results[name]['test_accuracies'][-1] for name in names]\n",
        "bars = plt.bar(names, accuracies, alpha=0.7)\n",
        "plt.title('Final Test Accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "             f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjnmyMxcX7bj"
      },
      "source": [
        "## 9. Best Model Analysis\n",
        "\n",
        "Here we will try to better analyze performance of the best model, covering different classification metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tlle0UTX7bj"
      },
      "outputs": [],
      "source": [
        "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['test_accuracies'][-1])\n",
        "best_model = model_results[best_model_name]['model']\n",
        "\n",
        "\n",
        "best_model.eval()\n",
        "test_probs = []\n",
        "test_labels = []\n",
        "test_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "        batch_features = batch_features.to(device)\n",
        "        outputs = best_model(batch_features)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        test_probs.extend(probs[:, 1].cpu().numpy())  # Probability of positive class\n",
        "        test_labels.extend(batch_labels.numpy())\n",
        "        test_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Physiological_Probability': test_probs,\n",
        "    'Predicted_Class': test_preds,\n",
        "    'True_Class': test_labels,\n",
        "})\n",
        "\n",
        "print(\"Prediction Analysis:\")\n",
        "print(f\"Total predictions: {len(results_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCAlzfjSX7bj"
      },
      "outputs": [],
      "source": [
        "results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqpQJTkBX7bj"
      },
      "source": [
        "### Basic metrics that require hard labels as predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7rBsMC_X7bk"
      },
      "outputs": [],
      "source": [
        "print(f\"Evaluating {best_model_name} model...\")\n",
        "\n",
        "# Calculate basic metrics\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "precision = precision_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds)\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "\n",
        "print(f\"\\nBasic Classification Metrics:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-Score:  {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgF1UQQBX7bk"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n=== Metric Interpretations ===\")\n",
        "print(f\"Accuracy:  Out of all predictions, what fraction were correct?\")\n",
        "print(f\"          {accuracy:.1%} of all predictions were correct\")\n",
        "print(f\"Precision: Out of all predicted positive cases, what fraction were actually positive?\")\n",
        "print(f\"          {precision:.1%} of predicted physiological dimers were actually physiological\")\n",
        "print(f\"Recall:    Out of all actual positive cases, what fraction did we catch?\")\n",
        "print(f\"          {recall:.1%} of actual physiological dimers were correctly identified\")\n",
        "print(f\"F1-Score:  Harmonic mean of precision and recall (balanced measure)\")\n",
        "print(f\"          {f1:.1%} - balanced performance between precision and recall\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYfOGPB3X7bk"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIIGokwAX7bk"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot 1: Basic confusion matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Non-physiological', 'Physiological'],\n",
        "            yticklabels=['Non-physiological', 'Physiological'])\n",
        "plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVvyQjjzX7bk"
      },
      "outputs": [],
      "source": [
        "cm_normalized = confusion_matrix(test_labels, test_preds, normalize='true')\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot 1: Basic confusion matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
        "            xticklabels=['Non-physiological', 'Physiological'],\n",
        "            yticklabels=['Non-physiological', 'Physiological'])\n",
        "plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMOCErfiX7bk"
      },
      "source": [
        "### Distribution of predicted probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qus8IU_-X7bk"
      },
      "outputs": [],
      "source": [
        "sns.violinplot(x=test_labels, y=test_probs)\n",
        "sns.swarmplot(x=test_labels, y=test_probs, color='black', alpha=0.5)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Probability of Physiological Class\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL_ans7rX7bk"
      },
      "source": [
        "### ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJmNw6uZX7bl"
      },
      "outputs": [],
      "source": [
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, roc_thresholds = roc_curve(test_labels, test_probs)\n",
        "roc_auc = roc_auc_score(test_labels, test_probs)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
        "plt.title(f'ROC Curve - {best_model_name}')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Explain ROC curve\n",
        "print(f\"\\n=== ROC Curve Explanation ===\")\n",
        "print(f\"ROC (Receiver Operating Characteristic) Curve:\")\n",
        "print(f\"- X-axis: False Positive Rate (FPR) = FP/(FP+TN)\")\n",
        "print(f\"- Y-axis: True Positive Rate (TPR) = TP/(TP+FN) = Recall\")\n",
        "print(f\"- AUC (Area Under Curve) = {roc_auc:.3f}\")\n",
        "print(f\"- Perfect classifier: AUC = 1.0\")\n",
        "print(f\"- Random classifier: AUC = 0.5\")\n",
        "print(f\"- Our model: AUC = {roc_auc:.3f} ({'Good' if roc_auc > 0.8 else 'Fair' if roc_auc > 0.7 else 'Poor'} performance)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoaveqAiX7bl"
      },
      "outputs": [],
      "source": [
        "# Show different threshold points\n",
        "threshold_points = [0.2, 0.5, 0.8]\n",
        "print(f\"\\nThreshold Analysis:\")\n",
        "for threshold in threshold_points:\n",
        "    idx = np.argmin(np.abs(roc_thresholds - threshold))\n",
        "    fpr_val = fpr[idx]\n",
        "    tpr_val = tpr[idx]\n",
        "    print(f\"Threshold {threshold:.1f}: FPR={fpr_val:.3f}, TPR={tpr_val:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knXrldlUX7bl"
      },
      "source": [
        "### PR curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEBbjjKRX7bl"
      },
      "outputs": [],
      "source": [
        "precision_curve, recall_curve, pr_thresholds = precision_recall_curve(test_labels, test_probs)\n",
        "pr_auc = average_precision_score(test_labels, test_probs)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(recall_curve, precision_curve, color='red', lw=2, label=f'PR curve (AP = {pr_auc:.3f})')\n",
        "plt.axhline(y=np.mean(test_labels), color='navy', linestyle='--',\n",
        "            label=f'Random classifier (AP = {np.mean(test_labels):.3f})')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall (Sensitivity)')\n",
        "plt.ylabel('Precision')\n",
        "plt.title(f'Precision-Recall Curve - {best_model_name}')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Explain Precision-Recall curve\n",
        "print(f\"\\n=== Precision-Recall Curve Explanation ===\")\n",
        "print(f\"Precision-Recall Curve:\")\n",
        "print(f\"- X-axis: Recall (Sensitivity) = TP/(TP+FN)\")\n",
        "print(f\"- Y-axis: Precision = TP/(TP+FP)\")\n",
        "print(f\"- AP (Average Precision) = {pr_auc:.3f}\")\n",
        "print(f\"- Perfect classifier: AP = 1.0\")\n",
        "print(f\"- Random classifier: AP = proportion of positive class = {np.mean(test_labels):.3f}\")\n",
        "print(f\"- Our model: AP = {pr_auc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRpGLd8BX7bl"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nWhy PR Curve Matters for Imbalanced Data:\")\n",
        "print(f\"- Our dataset has {np.mean(test_labels):.1%} positive cases\")\n",
        "print(f\"- ROC curve can be misleading for imbalanced data\")\n",
        "print(f\"- PR curve focuses on the positive class performance\")\n",
        "print(f\"- Better metric for imbalanced classification problems\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJQLFDFNX7bl"
      },
      "source": [
        "## 10. Threshold Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOfZ6zd5X7bm"
      },
      "outputs": [],
      "source": [
        "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "threshold_metrics = []\n",
        "\n",
        "print(f\"\\n=== Threshold Analysis ===\")\n",
        "print(f\"Analyzing how different probability thresholds affect metrics:\")\n",
        "\n",
        "for threshold in thresholds:\n",
        "    # Apply threshold\n",
        "    predictions_threshold = (np.array(test_probs) >= threshold).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(test_labels, predictions_threshold)\n",
        "    prec = precision_score(test_labels, predictions_threshold)\n",
        "    rec = recall_score(test_labels, predictions_threshold)\n",
        "    f1 = f1_score(test_labels, predictions_threshold)\n",
        "\n",
        "    threshold_metrics.append({\n",
        "        'threshold': threshold,\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1\n",
        "    })\n",
        "\n",
        "    print(f\"Threshold {threshold:.1f}: Acc={acc:.3f}, Prec={prec:.3f}, Rec={rec:.3f}, F1={f1:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_N5Wvq1X7bm"
      },
      "outputs": [],
      "source": [
        "threshold_df = pd.DataFrame(threshold_metrics)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(threshold_df['threshold'], threshold_df['accuracy'], 'o-', label='Accuracy')\n",
        "plt.xlabel('Classification Threshold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs Threshold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(threshold_df['threshold'], threshold_df['precision'], 'o-', label='Precision')\n",
        "plt.xlabel('Classification Threshold')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision vs Threshold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(threshold_df['threshold'], threshold_df['recall'], 'o-', label='Recall')\n",
        "plt.xlabel('Classification Threshold')\n",
        "plt.ylabel('Recall')\n",
        "plt.xlabel('Classification Threshold')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall vs Threshold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(threshold_df['threshold'], threshold_df['f1'], 'o-', label='F1-Score')\n",
        "plt.xlabel('Classification Threshold')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.title('F1-Score vs Threshold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4Q4Q6nVX7bm"
      },
      "outputs": [],
      "source": [
        "optimal_idx = np.argmax(threshold_df['f1'])\n",
        "optimal_threshold = threshold_df.iloc[optimal_idx]['threshold']\n",
        "optimal_f1 = threshold_df.iloc[optimal_idx]['f1']\n",
        "\n",
        "print(f\"\\nOptimal Threshold Analysis:\")\n",
        "print(f\"Best F1-Score: {optimal_f1:.3f} at threshold {optimal_threshold:.1f}\")\n",
        "print(f\"This threshold balances precision and recall optimally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX4yylQ3X7bm"
      },
      "source": [
        "## What are the most problematic observations?\n",
        "\n",
        "We have a column **difficult**, which indicates dimers that are harder to classify, we want to check how our model works for them:\n",
        "\n",
        "- Make another train/test split but where **difficult** observations are only in test set (the same 0.2 ratio).\n",
        "- Train the best model.\n",
        "- Test it and check how the model performed to **difficult** targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo9eVE_sX7bm"
      },
      "outputs": [],
      "source": [
        "df[[\"physiological\", \"difficult\"]].value_counts()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python VIB course",
      "language": "python",
      "name": "protein_dl"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}